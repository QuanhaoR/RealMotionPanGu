defaults:
  - _self_
  - datamodule: av2_stream
  #- model: RealMotion
  - model: RealMotion_llama

hydra:
  run:
    dir: ${output_dir}
  # output_subdir: ${output_dir}/hydra
  # job:
  #   chdir: True

seed: 2333
tag: ${model.tag}-${datamodule.tag}
output_dir: outputs/${tag}/${now:%Y%m%d-%H%M%S}

# add llama ckpt path
llama_path: "llama-7b-hf"

npus: 4
batch_size: 32
epochs: 80
checkpoint: #"/SSD_disk/users/renquanhao/RealMotion/outputs/RealMotion_llama-av2_3frame_30his/20260127-223612/checkpoints/epoch_8-minADE6_0.9986622333526611.ckpt"
submit:

callbacks:
  - _target_: pytorch_lightning.callbacks.ModelCheckpoint
    dirpath: ${output_dir}/checkpoints
    filename: epoch_{epoch}-minADE6_{minADE6}
    monitor: minADE6
    mode: min
    save_top_k: 10
    auto_insert_metric_name: False
  - _target_: pytorch_lightning.callbacks.RichModelSummary
    max_depth: 1
#  - _target_: pytorch_lightning.callbacks.RichProgressBar
  - _target_: pytorch_lightning.callbacks.TQDMProgressBar
  - _target_: pytorch_lightning.callbacks.LearningRateMonitor
    logging_interval: epoch
  
trainer:
  max_epochs: ${epochs}
  accelerator: npu
  devices: ${npus}
  strategy: ddp_find_unused_parameters_false
  gradient_clip_val: 5
  gradient_clip_algorithm: norm
  sync_batchnorm: true
  default_root_dir: ${output_dir}


